{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewplk/AI-HW4/blob/main/AI-HW4-1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRVUziqz7hB"
      },
      "source": [
        "# Assignment 4\n",
        "\n",
        "This is an basecode for assignment 4 of Artificial Intelligence class (CSCE-4613), Spring 2023\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ih72pU-4h0BT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NBXrZkzlhS"
      },
      "source": [
        "## Binary Network\n",
        "\n",
        "## Define a binary network class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XXkjOLlQh4B0"
      },
      "outputs": [],
      "source": [
        "class BinaryNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [4]):\n",
        "    super(BinaryNetwork, self).__init__()\n",
        "    self.network_dims = [2] + hidden_dims + [1]\n",
        "    self.layers = []\n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      activation = nn.Sigmoid()\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_O-MPTzxo1"
      },
      "source": [
        "### Define data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZU9RPLbqi-tL"
      },
      "outputs": [],
      "source": [
        "def generate_data(operator = \"AND\"):\n",
        "  assert operator in [\"AND\", \"OR\", \"XOR\", \"NOR\"], \"%s operator is not valid\" % operator\n",
        "  data = []\n",
        "  label = []\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      data.append([i, j])\n",
        "      if operator == \"AND\":\n",
        "        label.append(i & j)\n",
        "      elif operator == \"OR\":\n",
        "        label.append(i | j)\n",
        "      elif operator == \"XOR\":\n",
        "        label.append(i ^ j)\n",
        "      else:\n",
        "        label.append(not (i | j))\n",
        "  data = torch.as_tensor(data, dtype = torch.float32)\n",
        "  label = torch.as_tensor(label, dtype = torch.float32)\n",
        "  return data, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rKa_T9az3G6"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nbF7qM7LkqFc",
        "outputId": "52a57732-43ad-4de6-e009-532ce1badc82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinaryNetwork(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=5, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n",
            "[5/1000]. Loss: 0.5950. Accuracy: 75.00\n",
            "[10/1000]. Loss: 0.5703. Accuracy: 75.00\n",
            "[15/1000]. Loss: 0.5783. Accuracy: 75.00\n",
            "[20/1000]. Loss: 0.5452. Accuracy: 75.00\n",
            "[25/1000]. Loss: 0.5312. Accuracy: 75.00\n",
            "[30/1000]. Loss: 0.5210. Accuracy: 75.00\n",
            "[35/1000]. Loss: 0.5009. Accuracy: 75.00\n",
            "[40/1000]. Loss: 0.4839. Accuracy: 75.00\n",
            "[45/1000]. Loss: 0.4651. Accuracy: 75.00\n",
            "[50/1000]. Loss: 0.4436. Accuracy: 75.00\n",
            "[55/1000]. Loss: 0.4221. Accuracy: 75.00\n",
            "[60/1000]. Loss: 0.3994. Accuracy: 75.00\n",
            "[65/1000]. Loss: 0.3759. Accuracy: 75.00\n",
            "[70/1000]. Loss: 0.3523. Accuracy: 75.00\n",
            "[75/1000]. Loss: 0.3289. Accuracy: 75.00\n",
            "[80/1000]. Loss: 0.3057. Accuracy: 75.00\n",
            "[85/1000]. Loss: 0.2832. Accuracy: 100.00\n",
            "[90/1000]. Loss: 0.2613. Accuracy: 100.00\n",
            "[95/1000]. Loss: 0.2402. Accuracy: 100.00\n",
            "[100/1000]. Loss: 0.2203. Accuracy: 100.00\n",
            "[105/1000]. Loss: 0.2016. Accuracy: 100.00\n",
            "[110/1000]. Loss: 0.1842. Accuracy: 100.00\n",
            "[115/1000]. Loss: 0.1683. Accuracy: 100.00\n",
            "[120/1000]. Loss: 0.1538. Accuracy: 100.00\n",
            "[125/1000]. Loss: 0.1406. Accuracy: 100.00\n",
            "[130/1000]. Loss: 0.1288. Accuracy: 100.00\n",
            "[135/1000]. Loss: 0.1182. Accuracy: 100.00\n",
            "[140/1000]. Loss: 0.1087. Accuracy: 100.00\n",
            "[145/1000]. Loss: 0.1002. Accuracy: 100.00\n",
            "[150/1000]. Loss: 0.0925. Accuracy: 100.00\n",
            "[155/1000]. Loss: 0.0857. Accuracy: 100.00\n",
            "[160/1000]. Loss: 0.0796. Accuracy: 100.00\n",
            "[165/1000]. Loss: 0.0741. Accuracy: 100.00\n",
            "[170/1000]. Loss: 0.0691. Accuracy: 100.00\n",
            "[175/1000]. Loss: 0.0647. Accuracy: 100.00\n",
            "[180/1000]. Loss: 0.0607. Accuracy: 100.00\n",
            "[185/1000]. Loss: 0.0570. Accuracy: 100.00\n",
            "[190/1000]. Loss: 0.0537. Accuracy: 100.00\n",
            "[195/1000]. Loss: 0.0507. Accuracy: 100.00\n",
            "[200/1000]. Loss: 0.0479. Accuracy: 100.00\n",
            "[205/1000]. Loss: 0.0454. Accuracy: 100.00\n",
            "[210/1000]. Loss: 0.0431. Accuracy: 100.00\n",
            "[215/1000]. Loss: 0.0410. Accuracy: 100.00\n",
            "[220/1000]. Loss: 0.0391. Accuracy: 100.00\n",
            "[225/1000]. Loss: 0.0373. Accuracy: 100.00\n",
            "[230/1000]. Loss: 0.0356. Accuracy: 100.00\n",
            "[235/1000]. Loss: 0.0341. Accuracy: 100.00\n",
            "[240/1000]. Loss: 0.0326. Accuracy: 100.00\n",
            "[245/1000]. Loss: 0.0313. Accuracy: 100.00\n",
            "[250/1000]. Loss: 0.0301. Accuracy: 100.00\n",
            "[255/1000]. Loss: 0.0289. Accuracy: 100.00\n",
            "[260/1000]. Loss: 0.0278. Accuracy: 100.00\n",
            "[265/1000]. Loss: 0.0268. Accuracy: 100.00\n",
            "[270/1000]. Loss: 0.0258. Accuracy: 100.00\n",
            "[275/1000]. Loss: 0.0249. Accuracy: 100.00\n",
            "[280/1000]. Loss: 0.0241. Accuracy: 100.00\n",
            "[285/1000]. Loss: 0.0233. Accuracy: 100.00\n",
            "[290/1000]. Loss: 0.0225. Accuracy: 100.00\n",
            "[295/1000]. Loss: 0.0218. Accuracy: 100.00\n",
            "[300/1000]. Loss: 0.0212. Accuracy: 100.00\n",
            "[305/1000]. Loss: 0.0205. Accuracy: 100.00\n",
            "[310/1000]. Loss: 0.0199. Accuracy: 100.00\n",
            "[315/1000]. Loss: 0.0193. Accuracy: 100.00\n",
            "[320/1000]. Loss: 0.0188. Accuracy: 100.00\n",
            "[325/1000]. Loss: 0.0183. Accuracy: 100.00\n",
            "[330/1000]. Loss: 0.0178. Accuracy: 100.00\n",
            "[335/1000]. Loss: 0.0173. Accuracy: 100.00\n",
            "[340/1000]. Loss: 0.0169. Accuracy: 100.00\n",
            "[345/1000]. Loss: 0.0164. Accuracy: 100.00\n",
            "[350/1000]. Loss: 0.0160. Accuracy: 100.00\n",
            "[355/1000]. Loss: 0.0156. Accuracy: 100.00\n",
            "[360/1000]. Loss: 0.0153. Accuracy: 100.00\n",
            "[365/1000]. Loss: 0.0149. Accuracy: 100.00\n",
            "[370/1000]. Loss: 0.0145. Accuracy: 100.00\n",
            "[375/1000]. Loss: 0.0142. Accuracy: 100.00\n",
            "[380/1000]. Loss: 0.0139. Accuracy: 100.00\n",
            "[385/1000]. Loss: 0.0136. Accuracy: 100.00\n",
            "[390/1000]. Loss: 0.0133. Accuracy: 100.00\n",
            "[395/1000]. Loss: 0.0130. Accuracy: 100.00\n",
            "[400/1000]. Loss: 0.0127. Accuracy: 100.00\n",
            "[405/1000]. Loss: 0.0125. Accuracy: 100.00\n",
            "[410/1000]. Loss: 0.0122. Accuracy: 100.00\n",
            "[415/1000]. Loss: 0.0120. Accuracy: 100.00\n",
            "[420/1000]. Loss: 0.0117. Accuracy: 100.00\n",
            "[425/1000]. Loss: 0.0115. Accuracy: 100.00\n",
            "[430/1000]. Loss: 0.0113. Accuracy: 100.00\n",
            "[435/1000]. Loss: 0.0111. Accuracy: 100.00\n",
            "[440/1000]. Loss: 0.0109. Accuracy: 100.00\n",
            "[445/1000]. Loss: 0.0107. Accuracy: 100.00\n",
            "[450/1000]. Loss: 0.0105. Accuracy: 100.00\n",
            "[455/1000]. Loss: 0.0103. Accuracy: 100.00\n",
            "[460/1000]. Loss: 0.0101. Accuracy: 100.00\n",
            "[465/1000]. Loss: 0.0099. Accuracy: 100.00\n",
            "[470/1000]. Loss: 0.0098. Accuracy: 100.00\n",
            "[475/1000]. Loss: 0.0096. Accuracy: 100.00\n",
            "[480/1000]. Loss: 0.0095. Accuracy: 100.00\n",
            "[485/1000]. Loss: 0.0093. Accuracy: 100.00\n",
            "[490/1000]. Loss: 0.0091. Accuracy: 100.00\n",
            "[495/1000]. Loss: 0.0090. Accuracy: 100.00\n",
            "[500/1000]. Loss: 0.0089. Accuracy: 100.00\n",
            "[505/1000]. Loss: 0.0087. Accuracy: 100.00\n",
            "[510/1000]. Loss: 0.0086. Accuracy: 100.00\n",
            "[515/1000]. Loss: 0.0085. Accuracy: 100.00\n",
            "[520/1000]. Loss: 0.0083. Accuracy: 100.00\n",
            "[525/1000]. Loss: 0.0082. Accuracy: 100.00\n",
            "[530/1000]. Loss: 0.0081. Accuracy: 100.00\n",
            "[535/1000]. Loss: 0.0080. Accuracy: 100.00\n",
            "[540/1000]. Loss: 0.0079. Accuracy: 100.00\n",
            "[545/1000]. Loss: 0.0077. Accuracy: 100.00\n",
            "[550/1000]. Loss: 0.0076. Accuracy: 100.00\n",
            "[555/1000]. Loss: 0.0075. Accuracy: 100.00\n",
            "[560/1000]. Loss: 0.0074. Accuracy: 100.00\n",
            "[565/1000]. Loss: 0.0073. Accuracy: 100.00\n",
            "[570/1000]. Loss: 0.0072. Accuracy: 100.00\n",
            "[575/1000]. Loss: 0.0071. Accuracy: 100.00\n",
            "[580/1000]. Loss: 0.0070. Accuracy: 100.00\n",
            "[585/1000]. Loss: 0.0069. Accuracy: 100.00\n",
            "[590/1000]. Loss: 0.0069. Accuracy: 100.00\n",
            "[595/1000]. Loss: 0.0068. Accuracy: 100.00\n",
            "[600/1000]. Loss: 0.0067. Accuracy: 100.00\n",
            "[605/1000]. Loss: 0.0066. Accuracy: 100.00\n",
            "[610/1000]. Loss: 0.0065. Accuracy: 100.00\n",
            "[615/1000]. Loss: 0.0064. Accuracy: 100.00\n",
            "[620/1000]. Loss: 0.0064. Accuracy: 100.00\n",
            "[625/1000]. Loss: 0.0063. Accuracy: 100.00\n",
            "[630/1000]. Loss: 0.0062. Accuracy: 100.00\n",
            "[635/1000]. Loss: 0.0061. Accuracy: 100.00\n",
            "[640/1000]. Loss: 0.0061. Accuracy: 100.00\n",
            "[645/1000]. Loss: 0.0060. Accuracy: 100.00\n",
            "[650/1000]. Loss: 0.0059. Accuracy: 100.00\n",
            "[655/1000]. Loss: 0.0059. Accuracy: 100.00\n",
            "[660/1000]. Loss: 0.0058. Accuracy: 100.00\n",
            "[665/1000]. Loss: 0.0057. Accuracy: 100.00\n",
            "[670/1000]. Loss: 0.0057. Accuracy: 100.00\n",
            "[675/1000]. Loss: 0.0056. Accuracy: 100.00\n",
            "[680/1000]. Loss: 0.0055. Accuracy: 100.00\n",
            "[685/1000]. Loss: 0.0055. Accuracy: 100.00\n",
            "[690/1000]. Loss: 0.0054. Accuracy: 100.00\n",
            "[695/1000]. Loss: 0.0054. Accuracy: 100.00\n",
            "[700/1000]. Loss: 0.0053. Accuracy: 100.00\n",
            "[705/1000]. Loss: 0.0053. Accuracy: 100.00\n",
            "[710/1000]. Loss: 0.0052. Accuracy: 100.00\n",
            "[715/1000]. Loss: 0.0052. Accuracy: 100.00\n",
            "[720/1000]. Loss: 0.0051. Accuracy: 100.00\n",
            "[725/1000]. Loss: 0.0051. Accuracy: 100.00\n",
            "[730/1000]. Loss: 0.0050. Accuracy: 100.00\n",
            "[735/1000]. Loss: 0.0050. Accuracy: 100.00\n",
            "[740/1000]. Loss: 0.0049. Accuracy: 100.00\n",
            "[745/1000]. Loss: 0.0049. Accuracy: 100.00\n",
            "[750/1000]. Loss: 0.0048. Accuracy: 100.00\n",
            "[755/1000]. Loss: 0.0048. Accuracy: 100.00\n",
            "[760/1000]. Loss: 0.0047. Accuracy: 100.00\n",
            "[765/1000]. Loss: 0.0047. Accuracy: 100.00\n",
            "[770/1000]. Loss: 0.0046. Accuracy: 100.00\n",
            "[775/1000]. Loss: 0.0046. Accuracy: 100.00\n",
            "[780/1000]. Loss: 0.0045. Accuracy: 100.00\n",
            "[785/1000]. Loss: 0.0045. Accuracy: 100.00\n",
            "[790/1000]. Loss: 0.0045. Accuracy: 100.00\n",
            "[795/1000]. Loss: 0.0044. Accuracy: 100.00\n",
            "[800/1000]. Loss: 0.0044. Accuracy: 100.00\n",
            "[805/1000]. Loss: 0.0043. Accuracy: 100.00\n",
            "[810/1000]. Loss: 0.0043. Accuracy: 100.00\n",
            "[815/1000]. Loss: 0.0043. Accuracy: 100.00\n",
            "[820/1000]. Loss: 0.0042. Accuracy: 100.00\n",
            "[825/1000]. Loss: 0.0042. Accuracy: 100.00\n",
            "[830/1000]. Loss: 0.0042. Accuracy: 100.00\n",
            "[835/1000]. Loss: 0.0041. Accuracy: 100.00\n",
            "[840/1000]. Loss: 0.0041. Accuracy: 100.00\n",
            "[845/1000]. Loss: 0.0041. Accuracy: 100.00\n",
            "[850/1000]. Loss: 0.0040. Accuracy: 100.00\n",
            "[855/1000]. Loss: 0.0040. Accuracy: 100.00\n",
            "[860/1000]. Loss: 0.0040. Accuracy: 100.00\n",
            "[865/1000]. Loss: 0.0039. Accuracy: 100.00\n",
            "[870/1000]. Loss: 0.0039. Accuracy: 100.00\n",
            "[875/1000]. Loss: 0.0039. Accuracy: 100.00\n",
            "[880/1000]. Loss: 0.0038. Accuracy: 100.00\n",
            "[885/1000]. Loss: 0.0038. Accuracy: 100.00\n",
            "[890/1000]. Loss: 0.0038. Accuracy: 100.00\n",
            "[895/1000]. Loss: 0.0037. Accuracy: 100.00\n",
            "[900/1000]. Loss: 0.0037. Accuracy: 100.00\n",
            "[905/1000]. Loss: 0.0037. Accuracy: 100.00\n",
            "[910/1000]. Loss: 0.0037. Accuracy: 100.00\n",
            "[915/1000]. Loss: 0.0036. Accuracy: 100.00\n",
            "[920/1000]. Loss: 0.0036. Accuracy: 100.00\n",
            "[925/1000]. Loss: 0.0036. Accuracy: 100.00\n",
            "[930/1000]. Loss: 0.0035. Accuracy: 100.00\n",
            "[935/1000]. Loss: 0.0035. Accuracy: 100.00\n",
            "[940/1000]. Loss: 0.0035. Accuracy: 100.00\n",
            "[945/1000]. Loss: 0.0035. Accuracy: 100.00\n",
            "[950/1000]. Loss: 0.0034. Accuracy: 100.00\n",
            "[955/1000]. Loss: 0.0034. Accuracy: 100.00\n",
            "[960/1000]. Loss: 0.0034. Accuracy: 100.00\n",
            "[965/1000]. Loss: 0.0034. Accuracy: 100.00\n",
            "[970/1000]. Loss: 0.0033. Accuracy: 100.00\n",
            "[975/1000]. Loss: 0.0033. Accuracy: 100.00\n",
            "[980/1000]. Loss: 0.0033. Accuracy: 100.00\n",
            "[985/1000]. Loss: 0.0033. Accuracy: 100.00\n",
            "[990/1000]. Loss: 0.0033. Accuracy: 100.00\n",
            "[995/1000]. Loss: 0.0032. Accuracy: 100.00\n",
            "[1000/1000]. Loss: 0.0032. Accuracy: 100.00\n",
            "Final Accuracy: 100.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7960f48f0bb0>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = BinaryNetwork( hidden_dims= [5])\n",
        "model.train()\n",
        "print(model)\n",
        "operator = \"AND\"\n",
        "inputs, labels = generate_data(operator = operator)\n",
        "n_iters = 1000\n",
        "learning_rate = 0.1\n",
        "bce_loss_fn = nn.BCELoss()\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "threshold = 0.5\n",
        "\n",
        "losses = []\n",
        "\n",
        "for i in range(1, n_iters + 1):\n",
        "  outputs = model(inputs)\n",
        "  outputs = outputs.reshape(-1)\n",
        "\n",
        "  loss = bce_loss_fn(outputs, labels)\n",
        "  predictions = (outputs > threshold).long()\n",
        "\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  losses.append(loss.item()) #STORE THE LOSS VALUE\n",
        "\n",
        "  loss = loss.item() # Convert to Python Scalar\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  if i % 5 == 0:\n",
        "    print(\"[%d/%d]. Loss: %0.4f. Accuracy: %0.2f\" % (i, n_iters, loss, accuracy))\n",
        "\n",
        "model.eval()\n",
        "outputs = model(inputs)\n",
        "outputs = outputs.reshape(-1)\n",
        "predictions = (outputs > threshold).long()\n",
        "accuracy = (predictions == labels).float().mean() * 100.\n",
        "accuracy = accuracy.item()\n",
        "print(\"Final Accuracy: %0.2f\" % (accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"%s_Network.pth\" % operator)\n",
        "  # model.load_state_dict(torch.load(\"%s_Network.pth\" % operator)) # Load model in the next time you use\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5YlJ_I3NYg"
      },
      "source": [
        "## Digit Classification\n",
        "\n",
        "### Define Digit Classification Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI2eUjVG0Ssz"
      },
      "outputs": [],
      "source": [
        "class DigitNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [128]):\n",
        "    super(DigitNetwork, self).__init__()\n",
        "    self.network_dims = [28 * 28] + hidden_dims + [10]\n",
        "    self.layers = []\n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      if i < len(self.network_dims[1:]) - 1:\n",
        "        activation = nn.Sigmoid() # Hidden Layer\n",
        "      else:\n",
        "        activation = nn.Softmax(dim=1) # Last Layer\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = layer(x)\n",
        "    if self.training == False:\n",
        "      x = self.layers[-1](x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTjiev9CK4K"
      },
      "source": [
        "### Define Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnVAlP85SGs"
      },
      "outputs": [],
      "source": [
        "def create_data_generator(batch_size = 32, root = \"data\"):\n",
        "  train_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = True,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  test_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = False,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = False)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZSB2N3CTFd"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDmnwaOT66-S",
        "outputId": "5e71357f-0843-4778-9144-3f957e0c16cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 158455495.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 115587494.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 72323047.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22571716.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "DigitNetwork(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
            "    (1): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "Epoch [1/1]. Iter [1/1875]. Loss: 2.28. Accuracy: 6.25\n",
            "Epoch [1/1]. Iter [101/1875]. Loss: 0.09. Accuracy: 100.00\n",
            "Epoch [1/1]. Iter [201/1875]. Loss: 0.23. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [301/1875]. Loss: 0.22. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [401/1875]. Loss: 0.16. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [501/1875]. Loss: 0.69. Accuracy: 78.12\n",
            "Epoch [1/1]. Iter [601/1875]. Loss: 0.39. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [701/1875]. Loss: 0.50. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [801/1875]. Loss: 0.32. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [901/1875]. Loss: 0.36. Accuracy: 84.38\n",
            "Epoch [1/1]. Iter [1001/1875]. Loss: 0.37. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [1101/1875]. Loss: 0.48. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1201/1875]. Loss: 0.75. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1301/1875]. Loss: 0.43. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1401/1875]. Loss: 0.37. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [1501/1875]. Loss: 0.35. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [1601/1875]. Loss: 0.55. Accuracy: 81.25\n",
            "Epoch [1/1]. Iter [1701/1875]. Loss: 0.32. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [1801/1875]. Loss: 0.23. Accuracy: 90.62\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork(hidden_dims=[])\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 1\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"MNIST_Network.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nZTwv1CbGl"
      },
      "source": [
        "### Define the evaluation framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLbEk4QZ6_4K",
        "outputId": "60855dec-47cd-4490-88a6-f83385b4bdbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter [1/10000]. Accuracy: 100.00\n",
            "Iter [2001/10000]. Accuracy: 100.00\n",
            "Iter [4001/10000]. Accuracy: 0.00\n",
            "Iter [6001/10000]. Accuracy: 100.00\n",
            "Iter [8001/10000]. Accuracy: 100.00\n",
            "Final Accuracy: 90.94\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 1\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork(hidden_dims=[])\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(\"MNIST_Network.pth\"))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmpi69Q-bzDj"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "### ReLU Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWoO_sciAqDa"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-defining-new-autograd-functions\n",
        "class MyReLU(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJY_Gnvb7wP"
      },
      "source": [
        "#### Sigmoid Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj3ac-EVRvMz"
      },
      "outputs": [],
      "source": [
        "class MySigmoid(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        ctx.save_for_backward(input)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of sigmoid function\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgjRo-W1b_CD"
      },
      "source": [
        "#### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyxyWGNaXvG_"
      },
      "outputs": [],
      "source": [
        "class MyLinearFunction(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weights, bias):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        # weights is a C x D tensor, C and D are the dimension out input and ouput\n",
        "        # bias is D tensor\n",
        "        ctx.save_for_backward(input, weights, bias)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of linear function\n",
        "        return torch.matmul(input, weights) + bias\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weights, bias = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input, grad_weights, grad_bias\n",
        "\n",
        "class MyLinearLayer(nn.Module):\n",
        "  # You don't modify this layer\n",
        "  def __init__(self, in_features = 2, out_features = 4):\n",
        "    super(MyLinearLayer, self).__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
        "    self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "    self.linear_fn = MyLinearFunction.apply\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.linear_fn(input, self.weights, self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjXs20ecGBG"
      },
      "source": [
        "#### Testing Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95fQHamjZMX1"
      },
      "outputs": [],
      "source": [
        "class MyLinearNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyLinearNetwork, self).__init__()\n",
        "    self.linear_1 = MyLinearLayer(28 * 28, 128)\n",
        "    self.sigmoid_fn = MySigmoid.apply\n",
        "    self.linear_2 = MyLinearLayer(128, 10)\n",
        "    self.softmax_fn = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    x = self.linear_1(x)\n",
        "    x = self.sigmoid_fn(x)\n",
        "    x = self.linear_2(x)\n",
        "    if self.training == False:\n",
        "      x = self.softmax_fn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PND4sBcwgM"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = MyLinearNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 3\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "model.eval()\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP5Vc_zriFmK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
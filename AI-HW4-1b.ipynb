{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewplk/AI-HW4/blob/main/AI-HW4-1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRVUziqz7hB"
      },
      "source": [
        "# Assignment 4\n",
        "\n",
        "This is an basecode for assignment 4 of Artificial Intelligence class (CSCE-4613), Spring 2023\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ih72pU-4h0BT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NBXrZkzlhS"
      },
      "source": [
        "## Binary Network\n",
        "\n",
        "## Define a binary network class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XXkjOLlQh4B0"
      },
      "outputs": [],
      "source": [
        "class BinaryNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [4]):\n",
        "    super(BinaryNetwork, self).__init__()\n",
        "    self.network_dims = [2] + hidden_dims + [1]\n",
        "    self.layers = []\n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      activation = nn.Sigmoid()\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_O-MPTzxo1"
      },
      "source": [
        "### Define data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZU9RPLbqi-tL"
      },
      "outputs": [],
      "source": [
        "def generate_data(operator = \"AND\"):\n",
        "  assert operator in [\"AND\", \"OR\", \"XOR\", \"NOR\"], \"%s operator is not valid\" % operator\n",
        "  data = []\n",
        "  label = []\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      data.append([i, j])\n",
        "      if operator == \"AND\":\n",
        "        label.append(i & j)\n",
        "      elif operator == \"OR\":\n",
        "        label.append(i | j)\n",
        "      elif operator == \"XOR\":\n",
        "        label.append(i ^ j)\n",
        "      else:\n",
        "        label.append(not (i | j))\n",
        "  data = torch.as_tensor(data, dtype = torch.float32)\n",
        "  label = torch.as_tensor(label, dtype = torch.float32)\n",
        "  return data, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rKa_T9az3G6"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nbF7qM7LkqFc",
        "outputId": "fb284cbd-58f5-4297-d225-fca92b73d700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinaryNetwork(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=5, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n",
            "[5/1000]. Loss: 0.6933. Accuracy: 50.00\n",
            "[10/1000]. Loss: 0.6933. Accuracy: 50.00\n",
            "[15/1000]. Loss: 0.6933. Accuracy: 75.00\n",
            "[20/1000]. Loss: 0.6932. Accuracy: 50.00\n",
            "[25/1000]. Loss: 0.6932. Accuracy: 50.00\n",
            "[30/1000]. Loss: 0.6931. Accuracy: 50.00\n",
            "[35/1000]. Loss: 0.6931. Accuracy: 50.00\n",
            "[40/1000]. Loss: 0.6931. Accuracy: 50.00\n",
            "[45/1000]. Loss: 0.6930. Accuracy: 50.00\n",
            "[50/1000]. Loss: 0.6930. Accuracy: 50.00\n",
            "[55/1000]. Loss: 0.6930. Accuracy: 50.00\n",
            "[60/1000]. Loss: 0.6929. Accuracy: 50.00\n",
            "[65/1000]. Loss: 0.6929. Accuracy: 50.00\n",
            "[70/1000]. Loss: 0.6929. Accuracy: 50.00\n",
            "[75/1000]. Loss: 0.6928. Accuracy: 50.00\n",
            "[80/1000]. Loss: 0.6928. Accuracy: 25.00\n",
            "[85/1000]. Loss: 0.6927. Accuracy: 50.00\n",
            "[90/1000]. Loss: 0.6927. Accuracy: 50.00\n",
            "[95/1000]. Loss: 0.6927. Accuracy: 50.00\n",
            "[100/1000]. Loss: 0.6926. Accuracy: 50.00\n",
            "[105/1000]. Loss: 0.6926. Accuracy: 50.00\n",
            "[110/1000]. Loss: 0.6925. Accuracy: 50.00\n",
            "[115/1000]. Loss: 0.6925. Accuracy: 50.00\n",
            "[120/1000]. Loss: 0.6924. Accuracy: 50.00\n",
            "[125/1000]. Loss: 0.6923. Accuracy: 50.00\n",
            "[130/1000]. Loss: 0.6923. Accuracy: 50.00\n",
            "[135/1000]. Loss: 0.6922. Accuracy: 50.00\n",
            "[140/1000]. Loss: 0.6921. Accuracy: 50.00\n",
            "[145/1000]. Loss: 0.6920. Accuracy: 50.00\n",
            "[150/1000]. Loss: 0.6920. Accuracy: 50.00\n",
            "[155/1000]. Loss: 0.6919. Accuracy: 50.00\n",
            "[160/1000]. Loss: 0.6917. Accuracy: 50.00\n",
            "[165/1000]. Loss: 0.6916. Accuracy: 50.00\n",
            "[170/1000]. Loss: 0.6915. Accuracy: 50.00\n",
            "[175/1000]. Loss: 0.6913. Accuracy: 50.00\n",
            "[180/1000]. Loss: 0.6912. Accuracy: 50.00\n",
            "[185/1000]. Loss: 0.6910. Accuracy: 50.00\n",
            "[190/1000]. Loss: 0.6908. Accuracy: 50.00\n",
            "[195/1000]. Loss: 0.6906. Accuracy: 50.00\n",
            "[200/1000]. Loss: 0.6904. Accuracy: 50.00\n",
            "[205/1000]. Loss: 0.6901. Accuracy: 75.00\n",
            "[210/1000]. Loss: 0.6898. Accuracy: 75.00\n",
            "[215/1000]. Loss: 0.6894. Accuracy: 75.00\n",
            "[220/1000]. Loss: 0.6891. Accuracy: 75.00\n",
            "[225/1000]. Loss: 0.6887. Accuracy: 75.00\n",
            "[230/1000]. Loss: 0.6882. Accuracy: 75.00\n",
            "[235/1000]. Loss: 0.6877. Accuracy: 75.00\n",
            "[240/1000]. Loss: 0.6871. Accuracy: 75.00\n",
            "[245/1000]. Loss: 0.6865. Accuracy: 75.00\n",
            "[250/1000]. Loss: 0.6857. Accuracy: 75.00\n",
            "[255/1000]. Loss: 0.6849. Accuracy: 75.00\n",
            "[260/1000]. Loss: 0.6840. Accuracy: 75.00\n",
            "[265/1000]. Loss: 0.6830. Accuracy: 75.00\n",
            "[270/1000]. Loss: 0.6819. Accuracy: 75.00\n",
            "[275/1000]. Loss: 0.6807. Accuracy: 75.00\n",
            "[280/1000]. Loss: 0.6793. Accuracy: 75.00\n",
            "[285/1000]. Loss: 0.6778. Accuracy: 75.00\n",
            "[290/1000]. Loss: 0.6762. Accuracy: 75.00\n",
            "[295/1000]. Loss: 0.6743. Accuracy: 75.00\n",
            "[300/1000]. Loss: 0.6723. Accuracy: 75.00\n",
            "[305/1000]. Loss: 0.6701. Accuracy: 75.00\n",
            "[310/1000]. Loss: 0.6677. Accuracy: 75.00\n",
            "[315/1000]. Loss: 0.6650. Accuracy: 75.00\n",
            "[320/1000]. Loss: 0.6620. Accuracy: 75.00\n",
            "[325/1000]. Loss: 0.6588. Accuracy: 75.00\n",
            "[330/1000]. Loss: 0.6553. Accuracy: 75.00\n",
            "[335/1000]. Loss: 0.6515. Accuracy: 75.00\n",
            "[340/1000]. Loss: 0.6473. Accuracy: 75.00\n",
            "[345/1000]. Loss: 0.6428. Accuracy: 75.00\n",
            "[350/1000]. Loss: 0.6379. Accuracy: 75.00\n",
            "[355/1000]. Loss: 0.6326. Accuracy: 75.00\n",
            "[360/1000]. Loss: 0.6270. Accuracy: 75.00\n",
            "[365/1000]. Loss: 0.6209. Accuracy: 75.00\n",
            "[370/1000]. Loss: 0.6145. Accuracy: 75.00\n",
            "[375/1000]. Loss: 0.6077. Accuracy: 75.00\n",
            "[380/1000]. Loss: 0.6006. Accuracy: 75.00\n",
            "[385/1000]. Loss: 0.5932. Accuracy: 75.00\n",
            "[390/1000]. Loss: 0.5855. Accuracy: 75.00\n",
            "[395/1000]. Loss: 0.5775. Accuracy: 75.00\n",
            "[400/1000]. Loss: 0.5693. Accuracy: 75.00\n",
            "[405/1000]. Loss: 0.5609. Accuracy: 75.00\n",
            "[410/1000]. Loss: 0.5524. Accuracy: 75.00\n",
            "[415/1000]. Loss: 0.5436. Accuracy: 75.00\n",
            "[420/1000]. Loss: 0.5348. Accuracy: 75.00\n",
            "[425/1000]. Loss: 0.5258. Accuracy: 75.00\n",
            "[430/1000]. Loss: 0.5167. Accuracy: 75.00\n",
            "[435/1000]. Loss: 0.5075. Accuracy: 75.00\n",
            "[440/1000]. Loss: 0.4981. Accuracy: 75.00\n",
            "[445/1000]. Loss: 0.4886. Accuracy: 75.00\n",
            "[450/1000]. Loss: 0.4789. Accuracy: 75.00\n",
            "[455/1000]. Loss: 0.4689. Accuracy: 75.00\n",
            "[460/1000]. Loss: 0.4587. Accuracy: 75.00\n",
            "[465/1000]. Loss: 0.4482. Accuracy: 75.00\n",
            "[470/1000]. Loss: 0.4374. Accuracy: 75.00\n",
            "[475/1000]. Loss: 0.4262. Accuracy: 75.00\n",
            "[480/1000]. Loss: 0.4146. Accuracy: 100.00\n",
            "[485/1000]. Loss: 0.4026. Accuracy: 100.00\n",
            "[490/1000]. Loss: 0.3903. Accuracy: 100.00\n",
            "[495/1000]. Loss: 0.3775. Accuracy: 100.00\n",
            "[500/1000]. Loss: 0.3645. Accuracy: 100.00\n",
            "[505/1000]. Loss: 0.3512. Accuracy: 100.00\n",
            "[510/1000]. Loss: 0.3376. Accuracy: 100.00\n",
            "[515/1000]. Loss: 0.3239. Accuracy: 100.00\n",
            "[520/1000]. Loss: 0.3101. Accuracy: 100.00\n",
            "[525/1000]. Loss: 0.2962. Accuracy: 100.00\n",
            "[530/1000]. Loss: 0.2825. Accuracy: 100.00\n",
            "[535/1000]. Loss: 0.2689. Accuracy: 100.00\n",
            "[540/1000]. Loss: 0.2556. Accuracy: 100.00\n",
            "[545/1000]. Loss: 0.2426. Accuracy: 100.00\n",
            "[550/1000]. Loss: 0.2300. Accuracy: 100.00\n",
            "[555/1000]. Loss: 0.2179. Accuracy: 100.00\n",
            "[560/1000]. Loss: 0.2063. Accuracy: 100.00\n",
            "[565/1000]. Loss: 0.1952. Accuracy: 100.00\n",
            "[570/1000]. Loss: 0.1847. Accuracy: 100.00\n",
            "[575/1000]. Loss: 0.1748. Accuracy: 100.00\n",
            "[580/1000]. Loss: 0.1655. Accuracy: 100.00\n",
            "[585/1000]. Loss: 0.1568. Accuracy: 100.00\n",
            "[590/1000]. Loss: 0.1486. Accuracy: 100.00\n",
            "[595/1000]. Loss: 0.1410. Accuracy: 100.00\n",
            "[600/1000]. Loss: 0.1339. Accuracy: 100.00\n",
            "[605/1000]. Loss: 0.1273. Accuracy: 100.00\n",
            "[610/1000]. Loss: 0.1212. Accuracy: 100.00\n",
            "[615/1000]. Loss: 0.1155. Accuracy: 100.00\n",
            "[620/1000]. Loss: 0.1102. Accuracy: 100.00\n",
            "[625/1000]. Loss: 0.1052. Accuracy: 100.00\n",
            "[630/1000]. Loss: 0.1006. Accuracy: 100.00\n",
            "[635/1000]. Loss: 0.0963. Accuracy: 100.00\n",
            "[640/1000]. Loss: 0.0923. Accuracy: 100.00\n",
            "[645/1000]. Loss: 0.0886. Accuracy: 100.00\n",
            "[650/1000]. Loss: 0.0851. Accuracy: 100.00\n",
            "[655/1000]. Loss: 0.0818. Accuracy: 100.00\n",
            "[660/1000]. Loss: 0.0787. Accuracy: 100.00\n",
            "[665/1000]. Loss: 0.0758. Accuracy: 100.00\n",
            "[670/1000]. Loss: 0.0731. Accuracy: 100.00\n",
            "[675/1000]. Loss: 0.0706. Accuracy: 100.00\n",
            "[680/1000]. Loss: 0.0682. Accuracy: 100.00\n",
            "[685/1000]. Loss: 0.0659. Accuracy: 100.00\n",
            "[690/1000]. Loss: 0.0638. Accuracy: 100.00\n",
            "[695/1000]. Loss: 0.0618. Accuracy: 100.00\n",
            "[700/1000]. Loss: 0.0599. Accuracy: 100.00\n",
            "[705/1000]. Loss: 0.0581. Accuracy: 100.00\n",
            "[710/1000]. Loss: 0.0564. Accuracy: 100.00\n",
            "[715/1000]. Loss: 0.0547. Accuracy: 100.00\n",
            "[720/1000]. Loss: 0.0532. Accuracy: 100.00\n",
            "[725/1000]. Loss: 0.0517. Accuracy: 100.00\n",
            "[730/1000]. Loss: 0.0504. Accuracy: 100.00\n",
            "[735/1000]. Loss: 0.0490. Accuracy: 100.00\n",
            "[740/1000]. Loss: 0.0478. Accuracy: 100.00\n",
            "[745/1000]. Loss: 0.0466. Accuracy: 100.00\n",
            "[750/1000]. Loss: 0.0454. Accuracy: 100.00\n",
            "[755/1000]. Loss: 0.0443. Accuracy: 100.00\n",
            "[760/1000]. Loss: 0.0432. Accuracy: 100.00\n",
            "[765/1000]. Loss: 0.0422. Accuracy: 100.00\n",
            "[770/1000]. Loss: 0.0413. Accuracy: 100.00\n",
            "[775/1000]. Loss: 0.0403. Accuracy: 100.00\n",
            "[780/1000]. Loss: 0.0394. Accuracy: 100.00\n",
            "[785/1000]. Loss: 0.0386. Accuracy: 100.00\n",
            "[790/1000]. Loss: 0.0378. Accuracy: 100.00\n",
            "[795/1000]. Loss: 0.0370. Accuracy: 100.00\n",
            "[800/1000]. Loss: 0.0362. Accuracy: 100.00\n",
            "[805/1000]. Loss: 0.0355. Accuracy: 100.00\n",
            "[810/1000]. Loss: 0.0348. Accuracy: 100.00\n",
            "[815/1000]. Loss: 0.0341. Accuracy: 100.00\n",
            "[820/1000]. Loss: 0.0334. Accuracy: 100.00\n",
            "[825/1000]. Loss: 0.0328. Accuracy: 100.00\n",
            "[830/1000]. Loss: 0.0322. Accuracy: 100.00\n",
            "[835/1000]. Loss: 0.0316. Accuracy: 100.00\n",
            "[840/1000]. Loss: 0.0310. Accuracy: 100.00\n",
            "[845/1000]. Loss: 0.0305. Accuracy: 100.00\n",
            "[850/1000]. Loss: 0.0300. Accuracy: 100.00\n",
            "[855/1000]. Loss: 0.0294. Accuracy: 100.00\n",
            "[860/1000]. Loss: 0.0289. Accuracy: 100.00\n",
            "[865/1000]. Loss: 0.0285. Accuracy: 100.00\n",
            "[870/1000]. Loss: 0.0280. Accuracy: 100.00\n",
            "[875/1000]. Loss: 0.0275. Accuracy: 100.00\n",
            "[880/1000]. Loss: 0.0271. Accuracy: 100.00\n",
            "[885/1000]. Loss: 0.0267. Accuracy: 100.00\n",
            "[890/1000]. Loss: 0.0262. Accuracy: 100.00\n",
            "[895/1000]. Loss: 0.0258. Accuracy: 100.00\n",
            "[900/1000]. Loss: 0.0255. Accuracy: 100.00\n",
            "[905/1000]. Loss: 0.0251. Accuracy: 100.00\n",
            "[910/1000]. Loss: 0.0247. Accuracy: 100.00\n",
            "[915/1000]. Loss: 0.0243. Accuracy: 100.00\n",
            "[920/1000]. Loss: 0.0240. Accuracy: 100.00\n",
            "[925/1000]. Loss: 0.0236. Accuracy: 100.00\n",
            "[930/1000]. Loss: 0.0233. Accuracy: 100.00\n",
            "[935/1000]. Loss: 0.0230. Accuracy: 100.00\n",
            "[940/1000]. Loss: 0.0227. Accuracy: 100.00\n",
            "[945/1000]. Loss: 0.0224. Accuracy: 100.00\n",
            "[950/1000]. Loss: 0.0221. Accuracy: 100.00\n",
            "[955/1000]. Loss: 0.0218. Accuracy: 100.00\n",
            "[960/1000]. Loss: 0.0215. Accuracy: 100.00\n",
            "[965/1000]. Loss: 0.0212. Accuracy: 100.00\n",
            "[970/1000]. Loss: 0.0209. Accuracy: 100.00\n",
            "[975/1000]. Loss: 0.0207. Accuracy: 100.00\n",
            "[980/1000]. Loss: 0.0204. Accuracy: 100.00\n",
            "[985/1000]. Loss: 0.0202. Accuracy: 100.00\n",
            "[990/1000]. Loss: 0.0199. Accuracy: 100.00\n",
            "[995/1000]. Loss: 0.0197. Accuracy: 100.00\n",
            "[1000/1000]. Loss: 0.0194. Accuracy: 100.00\n",
            "Final Accuracy: 100.00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a96098330a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = BinaryNetwork( hidden_dims= [5])\n",
        "model.train()\n",
        "print(model)\n",
        "operator = \"XOR\"\n",
        "inputs, labels = generate_data(operator = operator)\n",
        "n_iters = 1000\n",
        "learning_rate = 0.1\n",
        "bce_loss_fn = nn.BCELoss()\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "threshold = 0.5\n",
        "\n",
        "losses = []\n",
        "\n",
        "for i in range(1, n_iters + 1):\n",
        "  outputs = model(inputs)\n",
        "  outputs = outputs.reshape(-1)\n",
        "\n",
        "  loss = bce_loss_fn(outputs, labels)\n",
        "  predictions = (outputs > threshold).long()\n",
        "\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  losses.append(loss.item()) #STORE THE LOSS VALUE\n",
        "\n",
        "  loss = loss.item() # Convert to Python Scalar\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  if i % 5 == 0:\n",
        "    print(\"[%d/%d]. Loss: %0.4f. Accuracy: %0.2f\" % (i, n_iters, loss, accuracy))\n",
        "\n",
        "model.eval()\n",
        "outputs = model(inputs)\n",
        "outputs = outputs.reshape(-1)\n",
        "predictions = (outputs > threshold).long()\n",
        "accuracy = (predictions == labels).float().mean() * 100.\n",
        "accuracy = accuracy.item()\n",
        "print(\"Final Accuracy: %0.2f\" % (accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"%s_Network.pth\" % operator)\n",
        "  # model.load_state_dict(torch.load(\"%s_Network.pth\" % operator)) # Load model in the next time you use\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5YlJ_I3NYg"
      },
      "source": [
        "## Digit Classification\n",
        "\n",
        "### Define Digit Classification Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI2eUjVG0Ssz"
      },
      "outputs": [],
      "source": [
        "class DigitNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [128]):\n",
        "    super(DigitNetwork, self).__init__()\n",
        "    self.network_dims = [28 * 28] + hidden_dims + [10]\n",
        "    self.layers = []\n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      if i < len(self.network_dims[1:]) - 1:\n",
        "        activation = nn.Sigmoid() # Hidden Layer\n",
        "      else:\n",
        "        activation = nn.Softmax(dim=1) # Last Layer\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = layer(x)\n",
        "    if self.training == False:\n",
        "      x = self.layers[-1](x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTjiev9CK4K"
      },
      "source": [
        "### Define Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnVAlP85SGs"
      },
      "outputs": [],
      "source": [
        "def create_data_generator(batch_size = 32, root = \"data\"):\n",
        "  train_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = True,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  test_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = False,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = False)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZSB2N3CTFd"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDmnwaOT66-S",
        "outputId": "5e71357f-0843-4778-9144-3f957e0c16cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 158455495.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 115587494.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 72323047.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22571716.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "DigitNetwork(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
            "    (1): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "Epoch [1/1]. Iter [1/1875]. Loss: 2.28. Accuracy: 6.25\n",
            "Epoch [1/1]. Iter [101/1875]. Loss: 0.09. Accuracy: 100.00\n",
            "Epoch [1/1]. Iter [201/1875]. Loss: 0.23. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [301/1875]. Loss: 0.22. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [401/1875]. Loss: 0.16. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [501/1875]. Loss: 0.69. Accuracy: 78.12\n",
            "Epoch [1/1]. Iter [601/1875]. Loss: 0.39. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [701/1875]. Loss: 0.50. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [801/1875]. Loss: 0.32. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [901/1875]. Loss: 0.36. Accuracy: 84.38\n",
            "Epoch [1/1]. Iter [1001/1875]. Loss: 0.37. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [1101/1875]. Loss: 0.48. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1201/1875]. Loss: 0.75. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1301/1875]. Loss: 0.43. Accuracy: 87.50\n",
            "Epoch [1/1]. Iter [1401/1875]. Loss: 0.37. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [1501/1875]. Loss: 0.35. Accuracy: 90.62\n",
            "Epoch [1/1]. Iter [1601/1875]. Loss: 0.55. Accuracy: 81.25\n",
            "Epoch [1/1]. Iter [1701/1875]. Loss: 0.32. Accuracy: 93.75\n",
            "Epoch [1/1]. Iter [1801/1875]. Loss: 0.23. Accuracy: 90.62\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork(hidden_dims=[])\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 1\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"MNIST_Network.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nZTwv1CbGl"
      },
      "source": [
        "### Define the evaluation framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLbEk4QZ6_4K",
        "outputId": "60855dec-47cd-4490-88a6-f83385b4bdbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter [1/10000]. Accuracy: 100.00\n",
            "Iter [2001/10000]. Accuracy: 100.00\n",
            "Iter [4001/10000]. Accuracy: 0.00\n",
            "Iter [6001/10000]. Accuracy: 100.00\n",
            "Iter [8001/10000]. Accuracy: 100.00\n",
            "Final Accuracy: 90.94\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 1\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork(hidden_dims=[])\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(\"MNIST_Network.pth\"))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmpi69Q-bzDj"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "### ReLU Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWoO_sciAqDa"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-defining-new-autograd-functions\n",
        "class MyReLU(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJY_Gnvb7wP"
      },
      "source": [
        "#### Sigmoid Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj3ac-EVRvMz"
      },
      "outputs": [],
      "source": [
        "class MySigmoid(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        ctx.save_for_backward(input)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of sigmoid function\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgjRo-W1b_CD"
      },
      "source": [
        "#### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyxyWGNaXvG_"
      },
      "outputs": [],
      "source": [
        "class MyLinearFunction(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weights, bias):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        # weights is a C x D tensor, C and D are the dimension out input and ouput\n",
        "        # bias is D tensor\n",
        "        ctx.save_for_backward(input, weights, bias)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of linear function\n",
        "        return torch.matmul(input, weights) + bias\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weights, bias = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input, grad_weights, grad_bias\n",
        "\n",
        "class MyLinearLayer(nn.Module):\n",
        "  # You don't modify this layer\n",
        "  def __init__(self, in_features = 2, out_features = 4):\n",
        "    super(MyLinearLayer, self).__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
        "    self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "    self.linear_fn = MyLinearFunction.apply\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.linear_fn(input, self.weights, self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjXs20ecGBG"
      },
      "source": [
        "#### Testing Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95fQHamjZMX1"
      },
      "outputs": [],
      "source": [
        "class MyLinearNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyLinearNetwork, self).__init__()\n",
        "    self.linear_1 = MyLinearLayer(28 * 28, 128)\n",
        "    self.sigmoid_fn = MySigmoid.apply\n",
        "    self.linear_2 = MyLinearLayer(128, 10)\n",
        "    self.softmax_fn = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    x = self.linear_1(x)\n",
        "    x = self.sigmoid_fn(x)\n",
        "    x = self.linear_2(x)\n",
        "    if self.training == False:\n",
        "      x = self.softmax_fn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PND4sBcwgM"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = MyLinearNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 3\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "model.eval()\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP5Vc_zriFmK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}